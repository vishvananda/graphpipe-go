// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: tensorflow/core/framework/tensor.proto

package tensor_go_proto

import (
	encoding_binary "encoding/binary"
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	resource_handle_go_proto "github.com/vishvananda/graphpipe-go/cmd/graphpipe-tf/internal/github.com/tensorflow/tensorflow/tensorflow/go/core/framework/resource_handle_go_proto"
	tensor_shape_go_proto "github.com/vishvananda/graphpipe-go/cmd/graphpipe-tf/internal/github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto"
	types_go_proto "github.com/vishvananda/graphpipe-go/cmd/graphpipe-tf/internal/github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto"
	io "io"
	math "math"
	math_bits "math/bits"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

// Protocol buffer representing a tensor.
type TensorProto struct {
	Dtype types_go_proto.DataType `protobuf:"varint,1,opt,name=dtype,proto3,enum=tensorflow.DataType" json:"dtype,omitempty"`
	// Shape of the tensor.  TODO(touts): sort out the 0-rank issues.
	TensorShape *tensor_shape_go_proto.TensorShapeProto `protobuf:"bytes,2,opt,name=tensor_shape,json=tensorShape,proto3" json:"tensor_shape,omitempty"`
	// Version number.
	//
	// In version 0, if the "repeated xxx" representations contain only one
	// element, that element is repeated to fill the shape.  This makes it easy
	// to represent a constant Tensor with a single value.
	VersionNumber int32 `protobuf:"varint,3,opt,name=version_number,json=versionNumber,proto3" json:"version_number,omitempty"`
	// Serialized raw tensor content from either Tensor::AsProtoTensorContent or
	// memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
	// can be used for all tensor types. The purpose of this representation is to
	// reduce serialization overhead during RPC call by avoiding serialization of
	// many repeated small items.
	TensorContent []byte `protobuf:"bytes,4,opt,name=tensor_content,json=tensorContent,proto3" json:"tensor_content,omitempty"`
	// DT_HALF, DT_BFLOAT16. Note that since protobuf has no int16 type, we'll
	// have some pointless zero padding for each value here.
	HalfVal []int32 `protobuf:"varint,13,rep,packed,name=half_val,json=halfVal,proto3" json:"half_val,omitempty"`
	// DT_FLOAT.
	FloatVal []float32 `protobuf:"fixed32,5,rep,packed,name=float_val,json=floatVal,proto3" json:"float_val,omitempty"`
	// DT_DOUBLE.
	DoubleVal []float64 `protobuf:"fixed64,6,rep,packed,name=double_val,json=doubleVal,proto3" json:"double_val,omitempty"`
	// DT_INT32, DT_INT16, DT_INT8, DT_UINT8.
	IntVal []int32 `protobuf:"varint,7,rep,packed,name=int_val,json=intVal,proto3" json:"int_val,omitempty"`
	// DT_STRING
	StringVal [][]byte `protobuf:"bytes,8,rep,name=string_val,json=stringVal,proto3" json:"string_val,omitempty"`
	// DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
	// and imaginary parts of i-th single precision complex.
	ScomplexVal []float32 `protobuf:"fixed32,9,rep,packed,name=scomplex_val,json=scomplexVal,proto3" json:"scomplex_val,omitempty"`
	// DT_INT64
	Int64Val []int64 `protobuf:"varint,10,rep,packed,name=int64_val,json=int64Val,proto3" json:"int64_val,omitempty"`
	// DT_BOOL
	BoolVal []bool `protobuf:"varint,11,rep,packed,name=bool_val,json=boolVal,proto3" json:"bool_val,omitempty"`
	// DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
	// and imaginary parts of i-th double precision complex.
	DcomplexVal []float64 `protobuf:"fixed64,12,rep,packed,name=dcomplex_val,json=dcomplexVal,proto3" json:"dcomplex_val,omitempty"`
	// DT_RESOURCE
	ResourceHandleVal []*resource_handle_go_proto.ResourceHandleProto `protobuf:"bytes,14,rep,name=resource_handle_val,json=resourceHandleVal,proto3" json:"resource_handle_val,omitempty"`
	// DT_VARIANT
	VariantVal []*VariantTensorDataProto `protobuf:"bytes,15,rep,name=variant_val,json=variantVal,proto3" json:"variant_val,omitempty"`
	// DT_UINT32
	Uint32Val []uint32 `protobuf:"varint,16,rep,packed,name=uint32_val,json=uint32Val,proto3" json:"uint32_val,omitempty"`
	// DT_UINT64
	Uint64Val            []uint64 `protobuf:"varint,17,rep,packed,name=uint64_val,json=uint64Val,proto3" json:"uint64_val,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *TensorProto) Reset()         { *m = TensorProto{} }
func (m *TensorProto) String() string { return proto.CompactTextString(m) }
func (*TensorProto) ProtoMessage()    {}
func (*TensorProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_efa68180bc31e4fc, []int{0}
}
func (m *TensorProto) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TensorProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TensorProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TensorProto.Merge(m, src)
}
func (m *TensorProto) XXX_Size() int {
	return m.Size()
}
func (m *TensorProto) XXX_DiscardUnknown() {
	xxx_messageInfo_TensorProto.DiscardUnknown(m)
}

var xxx_messageInfo_TensorProto proto.InternalMessageInfo

func (m *TensorProto) GetDtype() types_go_proto.DataType {
	if m != nil {
		return m.Dtype
	}
	return types_go_proto.DataType_DT_INVALID
}

func (m *TensorProto) GetTensorShape() *tensor_shape_go_proto.TensorShapeProto {
	if m != nil {
		return m.TensorShape
	}
	return nil
}

func (m *TensorProto) GetVersionNumber() int32 {
	if m != nil {
		return m.VersionNumber
	}
	return 0
}

func (m *TensorProto) GetTensorContent() []byte {
	if m != nil {
		return m.TensorContent
	}
	return nil
}

func (m *TensorProto) GetHalfVal() []int32 {
	if m != nil {
		return m.HalfVal
	}
	return nil
}

func (m *TensorProto) GetFloatVal() []float32 {
	if m != nil {
		return m.FloatVal
	}
	return nil
}

func (m *TensorProto) GetDoubleVal() []float64 {
	if m != nil {
		return m.DoubleVal
	}
	return nil
}

func (m *TensorProto) GetIntVal() []int32 {
	if m != nil {
		return m.IntVal
	}
	return nil
}

func (m *TensorProto) GetStringVal() [][]byte {
	if m != nil {
		return m.StringVal
	}
	return nil
}

func (m *TensorProto) GetScomplexVal() []float32 {
	if m != nil {
		return m.ScomplexVal
	}
	return nil
}

func (m *TensorProto) GetInt64Val() []int64 {
	if m != nil {
		return m.Int64Val
	}
	return nil
}

func (m *TensorProto) GetBoolVal() []bool {
	if m != nil {
		return m.BoolVal
	}
	return nil
}

func (m *TensorProto) GetDcomplexVal() []float64 {
	if m != nil {
		return m.DcomplexVal
	}
	return nil
}

func (m *TensorProto) GetResourceHandleVal() []*resource_handle_go_proto.ResourceHandleProto {
	if m != nil {
		return m.ResourceHandleVal
	}
	return nil
}

func (m *TensorProto) GetVariantVal() []*VariantTensorDataProto {
	if m != nil {
		return m.VariantVal
	}
	return nil
}

func (m *TensorProto) GetUint32Val() []uint32 {
	if m != nil {
		return m.Uint32Val
	}
	return nil
}

func (m *TensorProto) GetUint64Val() []uint64 {
	if m != nil {
		return m.Uint64Val
	}
	return nil
}

// Protocol buffer representing the serialization format of DT_VARIANT tensors.
type VariantTensorDataProto struct {
	// Name of the type of objects being serialized.
	TypeName string `protobuf:"bytes,1,opt,name=type_name,json=typeName,proto3" json:"type_name,omitempty"`
	// Portions of the object that are not Tensors.
	Metadata []byte `protobuf:"bytes,2,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// Tensors contained within objects being serialized.
	Tensors              []*TensorProto `protobuf:"bytes,3,rep,name=tensors,proto3" json:"tensors,omitempty"`
	XXX_NoUnkeyedLiteral struct{}       `json:"-"`
	XXX_unrecognized     []byte         `json:"-"`
	XXX_sizecache        int32          `json:"-"`
}

func (m *VariantTensorDataProto) Reset()         { *m = VariantTensorDataProto{} }
func (m *VariantTensorDataProto) String() string { return proto.CompactTextString(m) }
func (*VariantTensorDataProto) ProtoMessage()    {}
func (*VariantTensorDataProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_efa68180bc31e4fc, []int{1}
}
func (m *VariantTensorDataProto) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VariantTensorDataProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *VariantTensorDataProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VariantTensorDataProto.Merge(m, src)
}
func (m *VariantTensorDataProto) XXX_Size() int {
	return m.Size()
}
func (m *VariantTensorDataProto) XXX_DiscardUnknown() {
	xxx_messageInfo_VariantTensorDataProto.DiscardUnknown(m)
}

var xxx_messageInfo_VariantTensorDataProto proto.InternalMessageInfo

func (m *VariantTensorDataProto) GetTypeName() string {
	if m != nil {
		return m.TypeName
	}
	return ""
}

func (m *VariantTensorDataProto) GetMetadata() []byte {
	if m != nil {
		return m.Metadata
	}
	return nil
}

func (m *VariantTensorDataProto) GetTensors() []*TensorProto {
	if m != nil {
		return m.Tensors
	}
	return nil
}

func init() {
	proto.RegisterType((*TensorProto)(nil), "tensorflow.TensorProto")
	proto.RegisterType((*VariantTensorDataProto)(nil), "tensorflow.VariantTensorDataProto")
}

func init() {
	proto.RegisterFile("tensorflow/core/framework/tensor.proto", fileDescriptor_efa68180bc31e4fc)
}

var fileDescriptor_efa68180bc31e4fc = []byte{
	// 590 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x84, 0x94, 0x4f, 0x6f, 0xd3, 0x30,
	0x18, 0xc6, 0xe5, 0x79, 0x5d, 0x53, 0x27, 0x1d, 0x5b, 0x40, 0x10, 0x6d, 0xac, 0x33, 0x93, 0x86,
	0x2c, 0x84, 0x5a, 0xd1, 0x21, 0xae, 0x48, 0x1b, 0x07, 0x2e, 0x8c, 0x29, 0x4c, 0x3b, 0x70, 0x89,
	0xdc, 0xc6, 0x6d, 0x23, 0x12, 0xbb, 0x72, 0xdc, 0x8d, 0xdd, 0x39, 0xf2, 0xc1, 0x38, 0xc2, 0x8d,
	0x23, 0xea, 0xa7, 0xe0, 0x88, 0xfc, 0x3a, 0x6d, 0x03, 0x6c, 0x70, 0x4b, 0x9e, 0xf7, 0xf7, 0x3e,
	0x8f, 0xff, 0xbc, 0x09, 0x79, 0x6c, 0x84, 0x2c, 0x95, 0x1e, 0xe5, 0xea, 0xaa, 0x37, 0x54, 0x5a,
	0xf4, 0x46, 0x9a, 0x17, 0xe2, 0x4a, 0xe9, 0x0f, 0x3d, 0x57, 0xe9, 0x4e, 0xb5, 0x32, 0x2a, 0x24,
	0x2b, 0x6e, 0xa7, 0x77, 0x7b, 0x8f, 0x16, 0xa5, 0x9a, 0xe9, 0xa1, 0x48, 0x26, 0x5c, 0xa6, 0xb9,
	0x70, 0xcd, 0x3b, 0x4f, 0xff, 0x17, 0x92, 0x94, 0x13, 0x3e, 0x5d, 0xd0, 0x87, 0xff, 0xa0, 0xaf,
	0xa7, 0xa2, 0x74, 0xd8, 0xc1, 0xb7, 0x06, 0xf1, 0xcf, 0x81, 0x3c, 0x83, 0x15, 0x3e, 0x21, 0x8d,
	0xd4, 0xd6, 0x23, 0x44, 0x11, 0xdb, 0xec, 0xdf, 0xeb, 0xae, 0x6c, 0xba, 0xaf, 0xb8, 0xe1, 0xe7,
	0xd7, 0x53, 0x11, 0x3b, 0x24, 0x7c, 0x49, 0x82, 0x7a, 0x70, 0xb4, 0x46, 0x11, 0xf3, 0xfb, 0x0f,
	0xeb, 0x2d, 0xce, 0xfa, 0x9d, 0x2d, 0x83, 0x7f, 0xec, 0x9b, 0x95, 0x12, 0x1e, 0x92, 0xcd, 0x4b,
	0xa1, 0xcb, 0x4c, 0xc9, 0x44, 0xce, 0x8a, 0x81, 0xd0, 0x11, 0xa6, 0x88, 0x35, 0xe2, 0x76, 0xa5,
	0x9e, 0x82, 0x68, 0xb1, 0x2a, 0x67, 0xa8, 0xa4, 0x11, 0xd2, 0x44, 0xeb, 0x14, 0xb1, 0x20, 0x6e,
	0x3b, 0xf5, 0xc4, 0x89, 0xe1, 0x1e, 0xf1, 0x26, 0x3c, 0x1f, 0x25, 0x97, 0x3c, 0x8f, 0xda, 0x14,
	0xb3, 0xc6, 0xf1, 0xda, 0x16, 0x8a, 0x9b, 0x56, 0xbb, 0xe0, 0x79, 0xb8, 0x4f, 0x5a, 0xa3, 0x5c,
	0x71, 0x03, 0xf5, 0x06, 0xc5, 0x6c, 0x0d, 0xea, 0x1e, 0x88, 0x16, 0x78, 0x44, 0x48, 0xaa, 0x66,
	0x83, 0x5c, 0x00, 0xb1, 0x41, 0x31, 0x43, 0x40, 0xb4, 0x9c, 0x6a, 0x91, 0x5d, 0xd2, 0xcc, 0xa4,
	0x73, 0x68, 0x2e, 0x13, 0x36, 0x32, 0x09, 0xfd, 0x7b, 0x84, 0x94, 0x46, 0x67, 0x72, 0x0c, 0x75,
	0x8f, 0x62, 0x16, 0xc4, 0x2d, 0xa7, 0xd8, 0xf2, 0x21, 0x09, 0xca, 0xa1, 0x2a, 0xa6, 0xb9, 0xf8,
	0x08, 0x40, 0x6b, 0xb9, 0x04, 0x7f, 0xa1, 0x57, 0xcb, 0xcc, 0xa4, 0x79, 0xf1, 0x1c, 0x18, 0x42,
	0x31, 0xc3, 0x6e, 0x99, 0x20, 0xba, 0x18, 0x6f, 0xa0, 0x54, 0x0e, 0x75, 0x9f, 0x62, 0xe6, 0xb9,
	0x6d, 0x5a, 0xad, 0x8a, 0x49, 0xeb, 0x31, 0xc1, 0x72, 0x1f, 0x7e, 0x5a, 0x8b, 0x79, 0x4b, 0xee,
	0xfe, 0x31, 0x65, 0x40, 0x6f, 0x52, 0xcc, 0xfc, 0xfe, 0x7e, 0xfd, 0x0a, 0xe3, 0x0a, 0x7b, 0x0d,
	0x94, 0xbb, 0xc5, 0x6d, 0xfd, 0x9b, 0x68, 0x0d, 0x4f, 0x88, 0x7f, 0xc9, 0x75, 0xc6, 0xab, 0xe3,
	0xb9, 0x03, 0x46, 0x07, 0x75, 0xa3, 0x0b, 0x57, 0x76, 0x23, 0x61, 0x67, 0xc9, 0x79, 0x91, 0xaa,
	0xad, 0xba, 0x82, 0x59, 0x26, 0xcd, 0x51, 0x1f, 0x3c, 0xb6, 0x28, 0x66, 0x6d, 0x77, 0x05, 0x4e,
	0xad, 0x21, 0xd5, 0x01, 0x6d, 0x53, 0xcc, 0xd6, 0x57, 0x08, 0x9c, 0xd0, 0xc1, 0x27, 0x44, 0xee,
	0xdf, 0x1c, 0x16, 0xee, 0x92, 0x96, 0x1d, 0xdd, 0x44, 0xf2, 0xc2, 0x8d, 0x78, 0x2b, 0xf6, 0xac,
	0x70, 0xca, 0x0b, 0x11, 0xee, 0x10, 0xaf, 0x10, 0x86, 0xa7, 0xdc, 0x70, 0x98, 0xe5, 0x20, 0x5e,
	0xbe, 0x87, 0xcf, 0x48, 0xd3, 0x6d, 0xa5, 0x8c, 0x30, 0x6c, 0xed, 0xc1, 0xdf, 0x63, 0xee, 0xf6,
	0xb3, 0xe0, 0x8e, 0x3f, 0xa3, 0x2f, 0xf3, 0x0e, 0xfa, 0x3a, 0xef, 0xa0, 0xef, 0xf3, 0x0e, 0xfa,
	0x31, 0xef, 0x20, 0x12, 0x29, 0x3d, 0xae, 0xf7, 0x2d, 0xbf, 0xc9, 0xe3, 0xa0, 0x66, 0x51, 0x9e,
	0xa1, 0xf7, 0x6f, 0xc6, 0x99, 0x99, 0xcc, 0x06, 0xdd, 0xa1, 0x2a, 0xea, 0x3f, 0x8a, 0x9b, 0x1f,
	0xc7, 0xea, 0x96, 0x1f, 0xc2, 0x58, 0x25, 0xf0, 0x99, 0xff, 0x44, 0x68, 0xb0, 0x01, 0x4f, 0x47,
	0xbf, 0x02, 0x00, 0x00, 0xff, 0xff, 0x8c, 0x8a, 0x59, 0x2e, 0xac, 0x04, 0x00, 0x00,
}

func (m *TensorProto) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TensorProto) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TensorProto) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.XXX_unrecognized != nil {
		i -= len(m.XXX_unrecognized)
		copy(dAtA[i:], m.XXX_unrecognized)
	}
	if len(m.Uint64Val) > 0 {
		dAtA2 := make([]byte, len(m.Uint64Val)*10)
		var j1 int
		for _, num := range m.Uint64Val {
			for num >= 1<<7 {
				dAtA2[j1] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j1++
			}
			dAtA2[j1] = uint8(num)
			j1++
		}
		i -= j1
		copy(dAtA[i:], dAtA2[:j1])
		i = encodeVarintTensor(dAtA, i, uint64(j1))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x8a
	}
	if len(m.Uint32Val) > 0 {
		dAtA4 := make([]byte, len(m.Uint32Val)*10)
		var j3 int
		for _, num := range m.Uint32Val {
			for num >= 1<<7 {
				dAtA4[j3] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j3++
			}
			dAtA4[j3] = uint8(num)
			j3++
		}
		i -= j3
		copy(dAtA[i:], dAtA4[:j3])
		i = encodeVarintTensor(dAtA, i, uint64(j3))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x82
	}
	if len(m.VariantVal) > 0 {
		for iNdEx := len(m.VariantVal) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.VariantVal[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintTensor(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x7a
		}
	}
	if len(m.ResourceHandleVal) > 0 {
		for iNdEx := len(m.ResourceHandleVal) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResourceHandleVal[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintTensor(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x72
		}
	}
	if len(m.HalfVal) > 0 {
		dAtA6 := make([]byte, len(m.HalfVal)*10)
		var j5 int
		for _, num1 := range m.HalfVal {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA6[j5] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j5++
			}
			dAtA6[j5] = uint8(num)
			j5++
		}
		i -= j5
		copy(dAtA[i:], dAtA6[:j5])
		i = encodeVarintTensor(dAtA, i, uint64(j5))
		i--
		dAtA[i] = 0x6a
	}
	if len(m.DcomplexVal) > 0 {
		for iNdEx := len(m.DcomplexVal) - 1; iNdEx >= 0; iNdEx-- {
			f7 := math.Float64bits(float64(m.DcomplexVal[iNdEx]))
			i -= 8
			encoding_binary.LittleEndian.PutUint64(dAtA[i:], uint64(f7))
		}
		i = encodeVarintTensor(dAtA, i, uint64(len(m.DcomplexVal)*8))
		i--
		dAtA[i] = 0x62
	}
	if len(m.BoolVal) > 0 {
		for iNdEx := len(m.BoolVal) - 1; iNdEx >= 0; iNdEx-- {
			i--
			if m.BoolVal[iNdEx] {
				dAtA[i] = 1
			} else {
				dAtA[i] = 0
			}
		}
		i = encodeVarintTensor(dAtA, i, uint64(len(m.BoolVal)))
		i--
		dAtA[i] = 0x5a
	}
	if len(m.Int64Val) > 0 {
		dAtA9 := make([]byte, len(m.Int64Val)*10)
		var j8 int
		for _, num1 := range m.Int64Val {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA9[j8] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j8++
			}
			dAtA9[j8] = uint8(num)
			j8++
		}
		i -= j8
		copy(dAtA[i:], dAtA9[:j8])
		i = encodeVarintTensor(dAtA, i, uint64(j8))
		i--
		dAtA[i] = 0x52
	}
	if len(m.ScomplexVal) > 0 {
		for iNdEx := len(m.ScomplexVal) - 1; iNdEx >= 0; iNdEx-- {
			f10 := math.Float32bits(float32(m.ScomplexVal[iNdEx]))
			i -= 4
			encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(f10))
		}
		i = encodeVarintTensor(dAtA, i, uint64(len(m.ScomplexVal)*4))
		i--
		dAtA[i] = 0x4a
	}
	if len(m.StringVal) > 0 {
		for iNdEx := len(m.StringVal) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.StringVal[iNdEx])
			copy(dAtA[i:], m.StringVal[iNdEx])
			i = encodeVarintTensor(dAtA, i, uint64(len(m.StringVal[iNdEx])))
			i--
			dAtA[i] = 0x42
		}
	}
	if len(m.IntVal) > 0 {
		dAtA12 := make([]byte, len(m.IntVal)*10)
		var j11 int
		for _, num1 := range m.IntVal {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA12[j11] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j11++
			}
			dAtA12[j11] = uint8(num)
			j11++
		}
		i -= j11
		copy(dAtA[i:], dAtA12[:j11])
		i = encodeVarintTensor(dAtA, i, uint64(j11))
		i--
		dAtA[i] = 0x3a
	}
	if len(m.DoubleVal) > 0 {
		for iNdEx := len(m.DoubleVal) - 1; iNdEx >= 0; iNdEx-- {
			f13 := math.Float64bits(float64(m.DoubleVal[iNdEx]))
			i -= 8
			encoding_binary.LittleEndian.PutUint64(dAtA[i:], uint64(f13))
		}
		i = encodeVarintTensor(dAtA, i, uint64(len(m.DoubleVal)*8))
		i--
		dAtA[i] = 0x32
	}
	if len(m.FloatVal) > 0 {
		for iNdEx := len(m.FloatVal) - 1; iNdEx >= 0; iNdEx-- {
			f14 := math.Float32bits(float32(m.FloatVal[iNdEx]))
			i -= 4
			encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(f14))
		}
		i = encodeVarintTensor(dAtA, i, uint64(len(m.FloatVal)*4))
		i--
		dAtA[i] = 0x2a
	}
	if len(m.TensorContent) > 0 {
		i -= len(m.TensorContent)
		copy(dAtA[i:], m.TensorContent)
		i = encodeVarintTensor(dAtA, i, uint64(len(m.TensorContent)))
		i--
		dAtA[i] = 0x22
	}
	if m.VersionNumber != 0 {
		i = encodeVarintTensor(dAtA, i, uint64(m.VersionNumber))
		i--
		dAtA[i] = 0x18
	}
	if m.TensorShape != nil {
		{
			size, err := m.TensorShape.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintTensor(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x12
	}
	if m.Dtype != 0 {
		i = encodeVarintTensor(dAtA, i, uint64(m.Dtype))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *VariantTensorDataProto) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VariantTensorDataProto) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VariantTensorDataProto) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.XXX_unrecognized != nil {
		i -= len(m.XXX_unrecognized)
		copy(dAtA[i:], m.XXX_unrecognized)
	}
	if len(m.Tensors) > 0 {
		for iNdEx := len(m.Tensors) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Tensors[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintTensor(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.Metadata) > 0 {
		i -= len(m.Metadata)
		copy(dAtA[i:], m.Metadata)
		i = encodeVarintTensor(dAtA, i, uint64(len(m.Metadata)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.TypeName) > 0 {
		i -= len(m.TypeName)
		copy(dAtA[i:], m.TypeName)
		i = encodeVarintTensor(dAtA, i, uint64(len(m.TypeName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func encodeVarintTensor(dAtA []byte, offset int, v uint64) int {
	offset -= sovTensor(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *TensorProto) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Dtype != 0 {
		n += 1 + sovTensor(uint64(m.Dtype))
	}
	if m.TensorShape != nil {
		l = m.TensorShape.Size()
		n += 1 + l + sovTensor(uint64(l))
	}
	if m.VersionNumber != 0 {
		n += 1 + sovTensor(uint64(m.VersionNumber))
	}
	l = len(m.TensorContent)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	if len(m.FloatVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.FloatVal)*4)) + len(m.FloatVal)*4
	}
	if len(m.DoubleVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.DoubleVal)*8)) + len(m.DoubleVal)*8
	}
	if len(m.IntVal) > 0 {
		l = 0
		for _, e := range m.IntVal {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.StringVal) > 0 {
		for _, b := range m.StringVal {
			l = len(b)
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if len(m.ScomplexVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.ScomplexVal)*4)) + len(m.ScomplexVal)*4
	}
	if len(m.Int64Val) > 0 {
		l = 0
		for _, e := range m.Int64Val {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.BoolVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.BoolVal))) + len(m.BoolVal)*1
	}
	if len(m.DcomplexVal) > 0 {
		n += 1 + sovTensor(uint64(len(m.DcomplexVal)*8)) + len(m.DcomplexVal)*8
	}
	if len(m.HalfVal) > 0 {
		l = 0
		for _, e := range m.HalfVal {
			l += sovTensor(uint64(e))
		}
		n += 1 + sovTensor(uint64(l)) + l
	}
	if len(m.ResourceHandleVal) > 0 {
		for _, e := range m.ResourceHandleVal {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if len(m.VariantVal) > 0 {
		for _, e := range m.VariantVal {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if len(m.Uint32Val) > 0 {
		l = 0
		for _, e := range m.Uint32Val {
			l += sovTensor(uint64(e))
		}
		n += 2 + sovTensor(uint64(l)) + l
	}
	if len(m.Uint64Val) > 0 {
		l = 0
		for _, e := range m.Uint64Val {
			l += sovTensor(uint64(e))
		}
		n += 2 + sovTensor(uint64(l)) + l
	}
	if m.XXX_unrecognized != nil {
		n += len(m.XXX_unrecognized)
	}
	return n
}

func (m *VariantTensorDataProto) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.TypeName)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	l = len(m.Metadata)
	if l > 0 {
		n += 1 + l + sovTensor(uint64(l))
	}
	if len(m.Tensors) > 0 {
		for _, e := range m.Tensors {
			l = e.Size()
			n += 1 + l + sovTensor(uint64(l))
		}
	}
	if m.XXX_unrecognized != nil {
		n += len(m.XXX_unrecognized)
	}
	return n
}

func sovTensor(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozTensor(x uint64) (n int) {
	return sovTensor(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *TensorProto) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TensorProto: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TensorProto: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Dtype", wireType)
			}
			m.Dtype = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Dtype |= types_go_proto.DataType(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorShape", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TensorShape == nil {
				m.TensorShape = &tensor_shape_go_proto.TensorShapeProto{}
			}
			if err := m.TensorShape.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field VersionNumber", wireType)
			}
			m.VersionNumber = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.VersionNumber |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorContent", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TensorContent = append(m.TensorContent[:0], dAtA[iNdEx:postIndex]...)
			if m.TensorContent == nil {
				m.TensorContent = []byte{}
			}
			iNdEx = postIndex
		case 5:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.FloatVal = append(m.FloatVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 4
				if elementCount != 0 && len(m.FloatVal) == 0 {
					m.FloatVal = make([]float32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.FloatVal = append(m.FloatVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field FloatVal", wireType)
			}
		case 6:
			if wireType == 1 {
				var v uint64
				if (iNdEx + 8) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
				iNdEx += 8
				v2 := float64(math.Float64frombits(v))
				m.DoubleVal = append(m.DoubleVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 8
				if elementCount != 0 && len(m.DoubleVal) == 0 {
					m.DoubleVal = make([]float64, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint64
					if (iNdEx + 8) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
					iNdEx += 8
					v2 := float64(math.Float64frombits(v))
					m.DoubleVal = append(m.DoubleVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DoubleVal", wireType)
			}
		case 7:
			if wireType == 0 {
				var v int32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int32(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.IntVal = append(m.IntVal, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.IntVal) == 0 {
					m.IntVal = make([]int32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v int32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.IntVal = append(m.IntVal, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field IntVal", wireType)
			}
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StringVal", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StringVal = append(m.StringVal, make([]byte, postIndex-iNdEx))
			copy(m.StringVal[len(m.StringVal)-1], dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 9:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.ScomplexVal = append(m.ScomplexVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 4
				if elementCount != 0 && len(m.ScomplexVal) == 0 {
					m.ScomplexVal = make([]float32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.ScomplexVal = append(m.ScomplexVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ScomplexVal", wireType)
			}
		case 10:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Int64Val = append(m.Int64Val, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.Int64Val) == 0 {
					m.Int64Val = make([]int64, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Int64Val = append(m.Int64Val, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Int64Val", wireType)
			}
		case 11:
			if wireType == 0 {
				var v int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.BoolVal = append(m.BoolVal, bool(v != 0))
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen
				if elementCount != 0 && len(m.BoolVal) == 0 {
					m.BoolVal = make([]bool, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.BoolVal = append(m.BoolVal, bool(v != 0))
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field BoolVal", wireType)
			}
		case 12:
			if wireType == 1 {
				var v uint64
				if (iNdEx + 8) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
				iNdEx += 8
				v2 := float64(math.Float64frombits(v))
				m.DcomplexVal = append(m.DcomplexVal, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 8
				if elementCount != 0 && len(m.DcomplexVal) == 0 {
					m.DcomplexVal = make([]float64, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint64
					if (iNdEx + 8) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
					iNdEx += 8
					v2 := float64(math.Float64frombits(v))
					m.DcomplexVal = append(m.DcomplexVal, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DcomplexVal", wireType)
			}
		case 13:
			if wireType == 0 {
				var v int32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int32(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.HalfVal = append(m.HalfVal, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.HalfVal) == 0 {
					m.HalfVal = make([]int32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v int32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.HalfVal = append(m.HalfVal, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field HalfVal", wireType)
			}
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResourceHandleVal", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResourceHandleVal = append(m.ResourceHandleVal, &resource_handle_go_proto.ResourceHandleProto{})
			if err := m.ResourceHandleVal[len(m.ResourceHandleVal)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field VariantVal", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.VariantVal = append(m.VariantVal, &VariantTensorDataProto{})
			if err := m.VariantVal[len(m.VariantVal)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 16:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= uint32(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Uint32Val = append(m.Uint32Val, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.Uint32Val) == 0 {
					m.Uint32Val = make([]uint32, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Uint32Val = append(m.Uint32Val, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Uint32Val", wireType)
			}
		case 17:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Uint64Val = append(m.Uint64Val, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowTensor
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthTensor
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthTensor
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 && len(m.Uint64Val) == 0 {
					m.Uint64Val = make([]uint64, 0, elementCount)
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowTensor
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Uint64Val = append(m.Uint64Val, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Uint64Val", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipTensor(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthTensor
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			m.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VariantTensorDataProto) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VariantTensorDataProto: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VariantTensorDataProto: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TypeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Metadata", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Metadata = append(m.Metadata[:0], dAtA[iNdEx:postIndex]...)
			if m.Metadata == nil {
				m.Metadata = []byte{}
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tensors", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthTensor
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthTensor
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tensors = append(m.Tensors, &TensorProto{})
			if err := m.Tensors[len(m.Tensors)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipTensor(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthTensor
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			m.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipTensor(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowTensor
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowTensor
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthTensor
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupTensor
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthTensor
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthTensor        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowTensor          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupTensor = fmt.Errorf("proto: unexpected end of group")
)
